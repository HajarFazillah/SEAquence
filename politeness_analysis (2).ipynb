{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76373c700ce24ca8b047b583ec263567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "Simulation",
              "LLM (CLOVA Studio)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "Mode:",
            "description_tooltip": null,
            "disabled": false,
            "icons": [],
            "index": 0,
            "layout": "IPY_MODEL_53ae775806dd490a9b3fa11fdc13ff91",
            "style": "IPY_MODEL_bf0f22adeb5f47c9bf6c872d0eb7be24",
            "tooltips": []
          }
        },
        "53ae775806dd490a9b3fa11fdc13ff91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0f22adeb5f47c9bf6c872d0eb7be24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8fZWvF8oXqA"
      },
      "source": [
        "# Talkativ: 공손성 분석 모듈 (Politeness Analysis)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 모듈 개요\n",
        "\n",
        "### 1.1 이 모듈의 목적\n",
        "\n",
        "공손성 분석 모듈은 사용자의 실제 발화를 분석하여 말투가 상황에 적절한지 평가하고 실시간 피드백을 제공하는 모듈입니다.\n",
        "\n",
        "한국어의 공손성(politeness)은 크게 두 가지 요소로 결정됩니다:\n",
        "\n",
        "1. **종결어미 (Sentence endings)**: -습니다, -요, -해 등\n",
        "2. **호칭 (Address terms)**: 님, 씨, 아/야 등\n",
        "\n",
        "이 모듈은 이 두 요소를 분석하여 발화의 공손성 수준을 점수화하고, 관계 분석 모듈에서 권장한 말투와 비교하여 적절성을 평가합니다.\n",
        "\n",
        "### 1.2 입력과 출력\n",
        "\n",
        "**입력:**\n",
        "- 사용자의 발화 텍스트\n",
        "- 권장 말투 수준 (관계 분석 모듈에서 제공)\n",
        "\n",
        "**출력:**\n",
        "- 공손성 점수 (0 ~ 100)\n",
        "- 실제 말투 수준 (informal / mixed / polite / very_polite)\n",
        "- 탐지된 패턴 (종결어미, 호칭 등)\n",
        "- 적절성 평가 및 피드백\n",
        "\n",
        "### 1.3 향후 확장 계획\n",
        "\n",
        "1. **AI-Hub 데이터 연동**: 실제 대화 데이터에서 공손성 패턴 학습\n",
        "2. **LLM 기반 피드백**: HyperCLOVA X를 활용한 자연스러운 피드백 생성\n",
        "3. **음성 분석 통합**: CLOVA Speech STT 결과와 연동\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lfur3IXQ--al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJs86UBloXqF",
        "outputId": "4657cc17-c8e1-42c1-b5ae-880067c70e69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "라이브러리 로드 완료\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "print(\"라이브러리 로드 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF5cuSAgfNr7",
        "outputId": "0f54846e-8b09-4a6c-a488-e17657b43424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "76373c700ce24ca8b047b583ec263567",
            "53ae775806dd490a9b3fa11fdc13ff91",
            "bf0f22adeb5f47c9bf6c872d0eb7be24"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Mode:', options=(('Simulation', False), ('LLM (CLOVA Studio)', True)), value=False)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76373c700ce24ca8b047b583ec263567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 모드: Simulation\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 실행 모드 설정 (Simulation / LLM)\n",
        "# ============================================================\n",
        "# - Simulation: 규칙 기반 분석 및 피드백만 수행합니다. API 키가 없어도 실행됩니다.\n",
        "# - LLM (CLOVA Studio): 규칙 기반 결과를 바탕으로, CLOVA Studio(HyperCLOVA X)로부터\n",
        "#   추가 피드백(요약/수정 제안/대체 문장)을 생성합니다.\n",
        "#\n",
        "# 설계 의도:\n",
        "# - 데모에서 동일한 입력에 대해 (1) 규칙 기반 결과와 (2) LLM 보강 결과를 비교할 수 있도록\n",
        "#   모드 전환을 단일 플래그(USE_LLM)로 제어합니다.\n",
        "# ============================================================\n",
        "\n",
        "USE_LLM = False  # ipywidgets가 없는 환경에서는 이 값을 수동으로 True/False로 바꾸면 됩니다.\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display\n",
        "\n",
        "    mode_toggle = widgets.ToggleButtons(\n",
        "        options=[(\"Simulation\", False), (\"LLM (CLOVA Studio)\", True)],\n",
        "        value=False,\n",
        "        description=\"Mode:\",\n",
        "        disabled=False,\n",
        "        button_style=\"\"\n",
        "    )\n",
        "\n",
        "    def _apply_mode(change):\n",
        "        global USE_LLM\n",
        "        USE_LLM = bool(change[\"new\"])\n",
        "\n",
        "    mode_toggle.observe(_apply_mode, names=\"value\")\n",
        "    display(mode_toggle)\n",
        "    print(\"현재 모드:\", \"LLM (CLOVA Studio)\" if mode_toggle.value else \"Simulation\")\n",
        "except Exception:\n",
        "    print(\"ipywidgets를 사용할 수 없습니다. USE_LLM 값을 수동으로 설정하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvipd5LCfNr8"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CLOVA Studio(OpenAI-compatible) 호출 유틸리티\n",
        "# ============================================================\n",
        "# 본 노트북은 OpenAI SDK를 사용하지 않고, requests로 HTTP POST를 직접 수행합니다.\n",
        "# 목적은 '외부 라이브러리 의존 최소화'와 '요청/응답 구조의 명시적 확인'입니다.\n",
        "#\n",
        "# API 키 주입 방식:\n",
        "# - 환경변수 CLOVASTUDIO_API_KEY 로 관리합니다.\n",
        "# - LLM 모드에서만 키 존재를 검사합니다(시뮬레이션 모드 실행 방해 방지).\n",
        "#\n",
        "# 엔드포인트:\n",
        "# - https://clovastudio.stream.ntruss.com/v1/openai/chat/completions\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "CLOVASTUDIO_BASE_URL = \"https://clovastudio.stream.ntruss.com/v1/openai\"\n",
        "CLOVASTUDIO_MODEL = \"HCX-005\"  # CLOVA Studio 콘솔에 표시된 모델명으로 정확히 일치시켜야 합니다.\n",
        "\n",
        "def _get_clovastudio_api_key() -> str:\n",
        "    key = os.getenv(\"CLOVASTUDIO_API_KEY\")\n",
        "    if not key:\n",
        "        raise RuntimeError(\n",
        "            \"LLM 모드에서 CLOVA Studio API 키가 필요합니다.\\n\"\n",
        "            \"환경변수 CLOVASTUDIO_API_KEY 를 설정하세요.\\n\"\n",
        "            \"예) export CLOVASTUDIO_API_KEY='발급받은_키'\"\n",
        "        )\n",
        "    return key\n",
        "\n",
        "def call_clovastudio_chat(system_prompt: str, user_text: str,\n",
        "                          temperature: float = 0.4, max_tokens: int = 256) -> str:\n",
        "    url = f\"{CLOVASTUDIO_BASE_URL}/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {_get_clovastudio_api_key()}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": CLOVASTUDIO_MODEL,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_text},\n",
        "        ],\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens,\n",
        "    }\n",
        "\n",
        "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    return data[\"choices\"][0][\"message\"][\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYQ53XvooXqG"
      },
      "source": [
        "## 2. 한국어 공손성 패턴 정의\n",
        "\n",
        "### 2.1 종결어미 패턴\n",
        "\n",
        "한국어 종결어미는 말투 수준을 결정하는 가장 중요한 요소입니다.\n",
        "\n",
        "| 수준 | 종결어미 | 점수 영향 |\n",
        "|------|---------|----------|\n",
        "| very_polite | -습니다, -습니까 | +30 |\n",
        "| polite | -요, -세요, -죠 | +20 |\n",
        "| informal | -해, -어, -야 | -20 |\n",
        "\n",
        "### 2.2 호칭 패턴\n",
        "\n",
        "| 호칭 | 점수 영향 | 사용 상황 |\n",
        "|------|----------|----------|\n",
        "| 님 | +15 | 높임 (교수님) |\n",
        "| 씨 | +5 | 일반 존중 |\n",
        "| 아/야 | -10 | 반말 호칭 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTmT1bHgoXqH",
        "outputId": "58dcdf98-4b83-4948-fbea-576a72276494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패턴 정의 완료\n",
            "- very_polite 종결어미: 5개\n",
            "- polite 종결어미: 9개\n",
            "- informal 종결어미: 9개\n"
          ]
        }
      ],
      "source": [
        "# 종결어미 패턴 정의\n",
        "ENDING_PATTERNS = {\n",
        "    \"very_polite\": [\n",
        "        r\"습니다[.?!]?$\",\n",
        "        r\"ㅂ니다[.?!]?$\",\n",
        "        r\"습니까[.?!]?$\",\n",
        "        r\"십시오[.?!]?$\",\n",
        "        r\"드리겠습니다[.?!]?$\",\n",
        "    ],\n",
        "    \"polite\": [\n",
        "        r\"해요[.?!]?$\",\n",
        "        r\"에요[.?!]?$\",\n",
        "        r\"예요[.?!]?$\",\n",
        "        r\"세요[.?!]?$\",\n",
        "        r\"죠[.?!]?$\",\n",
        "        r\"요[.?!]?$\",\n",
        "        r\"네요[.?!]?$\",\n",
        "        r\"을까요[.?!]?$\",\n",
        "        r\"ㄹ까요[.?!]?$\",\n",
        "    ],\n",
        "    \"informal\": [\n",
        "        r\"해[.?!]?$\",\n",
        "        r\"어[.?!]?$\",\n",
        "        r\"아[.?!]?$\",\n",
        "        r\"야[.?!]?$\",\n",
        "        r\"지[.?!]?$\",\n",
        "        r\"냐[.?!]?$\",\n",
        "        r\"니[.?!]?$\",\n",
        "        r\"거야[.?!]?$\",\n",
        "        r\"잖아[.?!]?$\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 호칭 패턴 정의\n",
        "HONORIFIC_PATTERNS = {\n",
        "    \"nim\": {\"pattern\": r\"[가-힣]+님\", \"score_delta\": 15, \"description\": \"높임 호칭 (님)\"},\n",
        "    \"ssi\": {\"pattern\": r\"[가-힣]+씨\", \"score_delta\": 5, \"description\": \"일반 존칭 (씨)\"},\n",
        "    \"ah_ya\": {\"pattern\": r\"[가-힣]+[아야](?![가-힣])\", \"score_delta\": -10, \"description\": \"반말 호칭 (아/야)\"}\n",
        "}\n",
        "\n",
        "# 높임 어휘 정의\n",
        "HONORIFIC_WORDS = {\n",
        "    \"high_level\": {\n",
        "        \"words\": [\"드리\", \"여쭙\", \"뵙\", \"모시\", \"계시\", \"주무시\"],\n",
        "        \"score_delta\": 10,\n",
        "        \"description\": \"높임 어휘\"\n",
        "    },\n",
        "    \"softener\": {\n",
        "        \"words\": [\"혹시\", \"괜찮으시다면\", \"실례지만\", \"죄송하지만\"],\n",
        "        \"score_delta\": 5,\n",
        "        \"description\": \"완곡 표현\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# 무례 표현 패턴\n",
        "RUDE_PATTERNS = {\n",
        "    \"direct_you\": {\"pattern\": r\"너(?![무희])\", \"score_delta\": -15, \"description\": \"직접적인 '너' 사용\"},\n",
        "    \"exclamation\": {\"pattern\": r\"야!\", \"score_delta\": -15, \"description\": \"야! 사용\"},\n",
        "    \"rude_question\": {\"pattern\": r\"뭐야|왜그래|뭔데\", \"score_delta\": -10, \"description\": \"무례한 질문\"}\n",
        "}\n",
        "\n",
        "print(\"패턴 정의 완료\")\n",
        "print(f\"- very_polite 종결어미: {len(ENDING_PATTERNS['very_polite'])}개\")\n",
        "print(f\"- polite 종결어미: {len(ENDING_PATTERNS['polite'])}개\")\n",
        "print(f\"- informal 종결어미: {len(ENDING_PATTERNS['informal'])}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LufNVDroXqI"
      },
      "source": [
        "## 3. 공손성 분석기 구현\n",
        "\n",
        "### 3.1 점수 계산 알고리즘\n",
        "\n",
        "기본 점수 50점에서 시작하여 다음 규칙으로 가감:\n",
        "\n",
        "```\n",
        "최종점수 = 50 (기본)\n",
        "         + 종결어미 점수 (+30/-20)\n",
        "         + 호칭 점수 (+15/-10)\n",
        "         + 높임어휘 점수 (+10)\n",
        "         + 무례표현 점수 (-15)\n",
        "```\n",
        "\n",
        "### 3.2 말투 수준 결정 기준\n",
        "\n",
        "- 80점 이상: very_polite\n",
        "- 60점 이상: polite\n",
        "- 40점 이상: mixed\n",
        "- 40점 미만: informal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG2icTfNoXqI",
        "outputId": "2e9cffdf-f0b6-4457-df5a-722d3f5a2ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KoreanPolitenessAnalyzer 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class PolitenessResult:\n",
        "    \"\"\"공손성 분석 결과\"\"\"\n",
        "    text: str\n",
        "    base_score: int = 50\n",
        "    final_score: int = 50\n",
        "    level: str = \"mixed\"\n",
        "    detected_endings: List[Dict] = field(default_factory=list)\n",
        "    detected_titles: List[Dict] = field(default_factory=list)\n",
        "    detected_honorifics: List[Dict] = field(default_factory=list)\n",
        "    detected_rude: List[Dict] = field(default_factory=list)\n",
        "    score_breakdown: Dict = field(default_factory=dict)\n",
        "    warnings: List[str] = field(default_factory=list)\n",
        "\n",
        "\n",
        "class KoreanPolitenessAnalyzer:\n",
        "    \"\"\"\n",
        "    한국어 공손성 분석기\n",
        "\n",
        "    텍스트를 입력받아 종결어미, 호칭, 높임 어휘 등을 분석하고\n",
        "    공손성 점수를 계산합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def analyze(self, text: str) -> PolitenessResult:\n",
        "        \"\"\"텍스트의 공손성 분석\"\"\"\n",
        "        result = PolitenessResult(text=text)\n",
        "        score = 50\n",
        "        breakdown = {\"base\": 50, \"endings\": 0, \"titles\": 0, \"honorifics\": 0, \"rude\": 0}\n",
        "\n",
        "        # 1. 종결어미 분석\n",
        "        ending_score, detected_endings = self._analyze_endings(text)\n",
        "        score += ending_score\n",
        "        breakdown[\"endings\"] = ending_score\n",
        "        result.detected_endings = detected_endings\n",
        "\n",
        "        # 2. 호칭 분석\n",
        "        title_score, detected_titles = self._analyze_titles(text)\n",
        "        score += title_score\n",
        "        breakdown[\"titles\"] = title_score\n",
        "        result.detected_titles = detected_titles\n",
        "\n",
        "        # 3. 높임 어휘 분석\n",
        "        honorific_score, detected_honorifics = self._analyze_honorific_words(text)\n",
        "        score += honorific_score\n",
        "        breakdown[\"honorifics\"] = honorific_score\n",
        "        result.detected_honorifics = detected_honorifics\n",
        "\n",
        "        # 4. 무례 표현 체크\n",
        "        rude_score, detected_rude, warnings = self._check_rude_patterns(text)\n",
        "        score += rude_score\n",
        "        breakdown[\"rude\"] = rude_score\n",
        "        result.detected_rude = detected_rude\n",
        "        result.warnings = warnings\n",
        "\n",
        "        # 5. 최종 점수 및 레벨 결정\n",
        "        result.final_score = max(0, min(100, score))\n",
        "        result.level = self._get_level(result.final_score)\n",
        "        result.score_breakdown = breakdown\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _analyze_endings(self, text: str) -> Tuple[int, List[Dict]]:\n",
        "        \"\"\"종결어미 분석\"\"\"\n",
        "        score_delta = 0\n",
        "        detected = []\n",
        "\n",
        "        sentences = re.split(r'[.!?]+', text)\n",
        "\n",
        "        for sent in sentences:\n",
        "            sent = sent.strip()\n",
        "            if not sent:\n",
        "                continue\n",
        "\n",
        "            found = False\n",
        "\n",
        "            # very_polite 패턴 체크\n",
        "            for pattern in ENDING_PATTERNS[\"very_polite\"]:\n",
        "                match = re.search(pattern, sent)\n",
        "                if match:\n",
        "                    score_delta += 30\n",
        "                    detected.append({\"level\": \"very_polite\", \"pattern\": match.group(), \"sentence\": sent, \"score_delta\": 30})\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                continue\n",
        "\n",
        "            # polite 패턴 체크\n",
        "            for pattern in ENDING_PATTERNS[\"polite\"]:\n",
        "                match = re.search(pattern, sent)\n",
        "                if match:\n",
        "                    score_delta += 20\n",
        "                    detected.append({\"level\": \"polite\", \"pattern\": match.group(), \"sentence\": sent, \"score_delta\": 20})\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                continue\n",
        "\n",
        "            # informal 패턴 체크\n",
        "            for pattern in ENDING_PATTERNS[\"informal\"]:\n",
        "                match = re.search(pattern, sent)\n",
        "                if match:\n",
        "                    score_delta -= 20\n",
        "                    detected.append({\"level\": \"informal\", \"pattern\": match.group(), \"sentence\": sent, \"score_delta\": -20})\n",
        "                    break\n",
        "\n",
        "        return score_delta, detected\n",
        "\n",
        "    def _analyze_titles(self, text: str) -> Tuple[int, List[Dict]]:\n",
        "        \"\"\"호칭 분석\"\"\"\n",
        "        score_delta = 0\n",
        "        detected = []\n",
        "\n",
        "        for name, info in HONORIFIC_PATTERNS.items():\n",
        "            matches = re.findall(info[\"pattern\"], text)\n",
        "            if matches:\n",
        "                score_delta += info[\"score_delta\"] * len(matches)\n",
        "                for match in matches:\n",
        "                    detected.append({\"type\": name, \"match\": match, \"score_delta\": info[\"score_delta\"]})\n",
        "\n",
        "        return score_delta, detected\n",
        "\n",
        "    def _analyze_honorific_words(self, text: str) -> Tuple[int, List[Dict]]:\n",
        "        \"\"\"높임 어휘 분석\"\"\"\n",
        "        score_delta = 0\n",
        "        detected = []\n",
        "\n",
        "        for category, info in HONORIFIC_WORDS.items():\n",
        "            for word in info[\"words\"]:\n",
        "                if word in text:\n",
        "                    score_delta += info[\"score_delta\"]\n",
        "                    detected.append({\"category\": category, \"word\": word, \"score_delta\": info[\"score_delta\"]})\n",
        "\n",
        "        return score_delta, detected\n",
        "\n",
        "    def _check_rude_patterns(self, text: str) -> Tuple[int, List[Dict], List[str]]:\n",
        "        \"\"\"무례 표현 체크\"\"\"\n",
        "        score_delta = 0\n",
        "        detected = []\n",
        "        warnings = []\n",
        "\n",
        "        for name, info in RUDE_PATTERNS.items():\n",
        "            match = re.search(info[\"pattern\"], text)\n",
        "            if match:\n",
        "                score_delta += info[\"score_delta\"]\n",
        "                detected.append({\"type\": name, \"match\": match.group(), \"score_delta\": info[\"score_delta\"]})\n",
        "                warnings.append(f\"주의: {info['description']} - '{match.group()}'\")\n",
        "\n",
        "        return score_delta, detected, warnings\n",
        "\n",
        "    def _get_level(self, score: int) -> str:\n",
        "        \"\"\"점수를 말투 수준으로 변환\"\"\"\n",
        "        if score >= 80:\n",
        "            return \"very_polite\"\n",
        "        elif score >= 60:\n",
        "            return \"polite\"\n",
        "        elif score >= 40:\n",
        "            return \"mixed\"\n",
        "        else:\n",
        "            return \"informal\"\n",
        "\n",
        "# 분석기 인스턴스 생성\n",
        "politeness_analyzer = KoreanPolitenessAnalyzer()\n",
        "print(\"KoreanPolitenessAnalyzer 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lRE44KaoXqK"
      },
      "source": [
        "## 4. 적절성 평가기 (Appropriateness Evaluator)\n",
        "\n",
        "권장 말투와 실제 말투를 비교하여 적절성을 평가합니다.\n",
        "\n",
        "### 4.1 평가 기준\n",
        "\n",
        "| 권장-실제 차이 | 평가 | 설명 |\n",
        "|--------------|------|------|\n",
        "| gap >= 2 | inappropriate | 말투가 많이 낮음 |\n",
        "| gap == 1 | caution | 조금 더 공손하면 좋겠음 |\n",
        "| gap == 0 | appropriate | 적절한 말투 |\n",
        "| gap < 0 | very_polite | 기대 이상으로 공손 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdEBf0xWoXqL",
        "outputId": "94d60369-d45c-47e7-d31e-c14ab39a704a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AppropriatenessEvaluator 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "class AppropriatenessEvaluator:\n",
        "    \"\"\"\n",
        "    적절성 평가기\n",
        "\n",
        "    권장 말투와 실제 말투를 비교하여 적절성을 평가하고\n",
        "    피드백을 생성합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    LEVEL_ORDER = [\"informal\", \"mixed\", \"polite\", \"very_polite\"]\n",
        "\n",
        "    def evaluate(self, recommended: str, actual: str) -> Dict:\n",
        "        \"\"\"\n",
        "        적절성 평가\n",
        "\n",
        "        Args:\n",
        "            recommended: 권장 말투 수준\n",
        "            actual: 실제 말투 수준\n",
        "\n",
        "        Returns:\n",
        "            평가 결과 딕셔너리\n",
        "        \"\"\"\n",
        "        rec_idx = self.LEVEL_ORDER.index(recommended)\n",
        "        act_idx = self.LEVEL_ORDER.index(actual)\n",
        "        gap = rec_idx - act_idx\n",
        "\n",
        "        if gap >= 2:\n",
        "            return {\n",
        "                \"status\": \"inappropriate\",\n",
        "                \"gap\": gap,\n",
        "                \"severity\": \"high\",\n",
        "                \"message\": \"말투가 상황에 비해 많이 낮습니다. 더 공손한 표현을 사용하세요.\",\n",
        "                \"recommended\": recommended,\n",
        "                \"actual\": actual\n",
        "            }\n",
        "        elif gap == 1:\n",
        "            return {\n",
        "                \"status\": \"caution\",\n",
        "                \"gap\": gap,\n",
        "                \"severity\": \"medium\",\n",
        "                \"message\": \"조금 더 공손한 표현이 좋겠습니다.\",\n",
        "                \"recommended\": recommended,\n",
        "                \"actual\": actual\n",
        "            }\n",
        "        elif gap == 0:\n",
        "            return {\n",
        "                \"status\": \"appropriate\",\n",
        "                \"gap\": gap,\n",
        "                \"severity\": \"none\",\n",
        "                \"message\": \"적절한 말투입니다!\",\n",
        "                \"recommended\": recommended,\n",
        "                \"actual\": actual\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"status\": \"very_polite\",\n",
        "                \"gap\": gap,\n",
        "                \"severity\": \"none\",\n",
        "                \"message\": \"매우 공손한 표현입니다! 상황에 따라 조금 편하게 말해도 괜찮아요.\",\n",
        "                \"recommended\": recommended,\n",
        "                \"actual\": actual\n",
        "            }\n",
        "\n",
        "    def generate_suggestion(self, text: str, recommended: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        개선된 표현 제안\n",
        "\n",
        "        향후 LLM API를 연동하여 더 자연스러운 제안을 생성할 예정입니다.\n",
        "        현재는 간단한 규칙 기반으로 제안합니다.\n",
        "        \"\"\"\n",
        "        suggestions = {\n",
        "            \"very_polite\": {\n",
        "                \"이거 어떻게 해\": \"이것은 어떻게 하면 될까요?\",\n",
        "                \"이거 뭐야\": \"이것이 무엇인가요?\",\n",
        "                \"왜\": \"왜 그런지 여쭤봐도 될까요?\",\n",
        "                \"알겠어\": \"알겠습니다\",\n",
        "                \"고마워\": \"감사합니다\"\n",
        "            },\n",
        "            \"polite\": {\n",
        "                \"이거 어떻게 해\": \"이거 어떻게 해요?\",\n",
        "                \"이거 뭐야\": \"이거 뭐예요?\",\n",
        "                \"왜\": \"왜요?\",\n",
        "                \"알겠어\": \"알겠어요\",\n",
        "                \"고마워\": \"고마워요\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if recommended in suggestions:\n",
        "            for informal, formal in suggestions[recommended].items():\n",
        "                if informal in text:\n",
        "                    return text.replace(informal, formal)\n",
        "\n",
        "        return None\n",
        "\n",
        "# 평가기 인스턴스 생성\n",
        "evaluator = AppropriatenessEvaluator()\n",
        "print(\"AppropriatenessEvaluator 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPE-eEVwoXqM"
      },
      "source": [
        "## 5. 통합 피드백 시스템\n",
        "\n",
        "공손성 분석과 적절성 평가를 통합하여 최종 피드백을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6BQe58roXqN",
        "outputId": "95dcfb2e-19a3-45ff-b78e-7a0b5028de07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PolitenessFeedbackSystem 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "class PolitenessFeedbackSystem:\n",
        "    \"\"\"\n",
        "    통합 피드백 시스템\n",
        "\n",
        "    공손성 분석 + 적절성 평가 + 피드백 생성을 통합합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.analyzer = KoreanPolitenessAnalyzer()\n",
        "        self.evaluator = AppropriatenessEvaluator()\n",
        "\n",
        "    def get_feedback(self, text: str, recommended_formality: str) -> Dict:\n",
        "        \"\"\"\n",
        "        전체 피드백 생성\n",
        "\n",
        "        Args:\n",
        "            text: 사용자 발화\n",
        "            recommended_formality: 권장 말투 수준\n",
        "\n",
        "        Returns:\n",
        "            종합 피드백 딕셔너리\n",
        "        \"\"\"\n",
        "        # 1. 공손성 분석\n",
        "        analysis = self.analyzer.analyze(text)\n",
        "\n",
        "        # 2. 적절성 평가\n",
        "        evaluation = self.evaluator.evaluate(recommended_formality, analysis.level)\n",
        "\n",
        "        # 3. 개선 제안 생성\n",
        "        suggestion = None\n",
        "        if evaluation[\"status\"] in [\"inappropriate\", \"caution\"]:\n",
        "            suggestion = self.evaluator.generate_suggestion(text, recommended_formality)\n",
        "\n",
        "        return {\n",
        "            \"input_text\": text,\n",
        "            \"analysis\": {\n",
        "                \"score\": analysis.final_score,\n",
        "                \"level\": analysis.level,\n",
        "                \"score_breakdown\": analysis.score_breakdown,\n",
        "                \"detected_patterns\": {\n",
        "                    \"endings\": analysis.detected_endings,\n",
        "                    \"titles\": analysis.detected_titles,\n",
        "                    \"honorifics\": analysis.detected_honorifics,\n",
        "                    \"rude\": analysis.detected_rude\n",
        "                },\n",
        "                \"warnings\": analysis.warnings\n",
        "            },\n",
        "            \"evaluation\": evaluation,\n",
        "            \"suggestion\": suggestion,\n",
        "            \"recommended_formality\": recommended_formality\n",
        "        }\n",
        "\n",
        "# 피드백 시스템 인스턴스 생성\n",
        "feedback_system = PolitenessFeedbackSystem()\n",
        "print(\"PolitenessFeedbackSystem 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEPo-oHLfNr_",
        "outputId": "f1797b1a-2bf6-44d4-834e-01e7d0f43099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get_feedback_by_mode 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 모드 기반 피드백 생성 (Simulation / LLM)\n",
        "# ============================================================\n",
        "# - 규칙 기반(get_feedback)은 항상 실행합니다.\n",
        "# - USE_LLM=True인 경우, 규칙 기반 분석 결과를 근거로 LLM에게\n",
        "#   (1) 평가 요약, (2) 수정 제안, (3) 대체 문장을 추가로 생성하도록 요청합니다.\n",
        "# - 결과는 feedback 딕셔너리에 llm_feedback 또는 llm_error 필드로 포함됩니다.\n",
        "# ============================================================\n",
        "\n",
        "def build_politeness_llm_prompt(text: str, recommended: str, analysis: Dict, evaluation: Dict) -> str:\n",
        "    score = analysis.get(\"score\")\n",
        "    actual_level = analysis.get(\"level\")\n",
        "    eval_msg = evaluation.get(\"message\")\n",
        "\n",
        "    return (\n",
        "        \"너는 한국어 공손성(말투) 코치다.\\n\"\n",
        "        \"주어진 입력 발화와 규칙 기반 분석 결과를 근거로, 사용자가 권장 말투에 맞추도록 도와라.\\n\"\n",
        "        \"출력은 한국어로, 아래 형식을 정확히 따른다.\\n\\n\"\n",
        "        \"[평가 요약]\\n\"\n",
        "        \"- (1~2문장)\\n\"\n",
        "        \"[수정 제안]\\n\"\n",
        "        \"- 제안 1\\n\"\n",
        "        \"- 제안 2\\n\"\n",
        "        \"[대체 문장]\\n\"\n",
        "        \"- 1문장\\n\\n\"\n",
        "        f\"입력 발화: {text}\\n\"\n",
        "        f\"권장 말투: {recommended}\\n\"\n",
        "        f\"규칙 기반 점수: {score}/100\\n\"\n",
        "        f\"규칙 기반 판정: {actual_level}\\n\"\n",
        "        f\"적절성 평가 메시지: {eval_msg}\\n\"\n",
        "        \"주의: 불필요한 장황한 설명은 피하고, 실용적인 교정에 집중한다.\"\n",
        "    )\n",
        "\n",
        "def get_feedback_by_mode(text: str, recommended_formality: str) -> Dict:\n",
        "    base_feedback = feedback_system.get_feedback(text=text, recommended_formality=recommended_formality)\n",
        "\n",
        "    if not USE_LLM:\n",
        "        base_feedback[\"mode\"] = \"simulation\"\n",
        "        return base_feedback\n",
        "\n",
        "    # LLM 모드: 규칙 기반 결과를 바탕으로 추가 피드백 생성\n",
        "    try:\n",
        "        analysis = base_feedback.get(\"analysis\", {})\n",
        "        evaluation = base_feedback.get(\"evaluation\", {})\n",
        "        system_prompt = build_politeness_llm_prompt(text, recommended_formality, analysis, evaluation)\n",
        "\n",
        "        llm_text = call_clovastudio_chat(\n",
        "            system_prompt=system_prompt,\n",
        "            user_text=\"위 형식에 맞춰 피드백을 생성해줘.\",\n",
        "            temperature=0.4,\n",
        "            max_tokens=256\n",
        "        )\n",
        "        base_feedback[\"mode\"] = \"llm\"\n",
        "        base_feedback[\"llm_feedback\"] = llm_text\n",
        "    except Exception as e:\n",
        "        base_feedback[\"mode\"] = \"llm\"\n",
        "        base_feedback[\"llm_error\"] = str(e)\n",
        "\n",
        "    return base_feedback\n",
        "\n",
        "print(\"get_feedback_by_mode 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmI_h2SCoXqN"
      },
      "source": [
        "## 6. 테스트 및 결과 분석\n",
        "\n",
        "다양한 시나리오로 공손성 분석을 테스트합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m7BuSAkoXqN"
      },
      "outputs": [],
      "source": [
        "def print_feedback_result(feedback: Dict):\n",
        "    \"\"\"피드백 결과를 보기 좋게 출력\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"입력: \\\"{feedback['input_text']}\\\"\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # 분석 결과\n",
        "    analysis = feedback['analysis']\n",
        "    print(f\"\\n[분석 결과]\")\n",
        "    print(f\"  공손성 점수: {analysis['score']}/100\")\n",
        "    print(f\"  판정 말투: {analysis['level']}\")\n",
        "    print(f\"  권장 말투: {feedback['recommended_formality']}\")\n",
        "\n",
        "    # 점수 상세\n",
        "    breakdown = analysis['score_breakdown']\n",
        "    print(f\"\\n[점수 상세]\")\n",
        "    print(f\"  기본 점수: {breakdown['base']}\")\n",
        "    print(f\"  종결어미: {breakdown['endings']:+d}\")\n",
        "    print(f\"  호칭: {breakdown['titles']:+d}\")\n",
        "    print(f\"  높임 어휘: {breakdown['honorifics']:+d}\")\n",
        "    print(f\"  무례 표현: {breakdown['rude']:+d}\")\n",
        "\n",
        "    # 탐지된 패턴\n",
        "    patterns = analysis['detected_patterns']\n",
        "    if patterns['endings']:\n",
        "        print(f\"\\n[탐지된 종결어미]\")\n",
        "        for e in patterns['endings']:\n",
        "            print(f\"  - {e['level']}: '{e['pattern']}' ({e['score_delta']:+d})\")\n",
        "\n",
        "    if patterns['titles']:\n",
        "        print(f\"\\n[탐지된 호칭]\")\n",
        "        for t in patterns['titles']:\n",
        "            print(f\"  - '{t['match']}' ({t['score_delta']:+d})\")\n",
        "\n",
        "    # 평가 결과\n",
        "    evaluation = feedback['evaluation']\n",
        "    print(f\"\\n[적절성 평가]\")\n",
        "    print(f\"  상태: {evaluation['status']}\")\n",
        "    print(f\"  메시지: {evaluation['message']}\")\n",
        "\n",
        "    # 개선 제안\n",
        "    if feedback['suggestion']:\n",
        "        print(f\"\\n[개선 제안]\")\n",
        "        print(f\"  추천 표현: \\\"{feedback['suggestion']}\\\"\")\n",
        "\n",
        "    # 경고\n",
        "    if analysis['warnings']:\n",
        "        print(f\"\\n[경고]\")\n",
        "        for w in analysis['warnings']:\n",
        "            print(f\"  - {w}\")\n",
        "\n",
        "    # 실행 모드\n",
        "    if 'mode' in feedback:\n",
        "        print(f\"\\n[실행 모드]\")\n",
        "        print(f\"  mode: {feedback['mode']}\")\n",
        "\n",
        "    # LLM 보강 피드백 (LLM 모드에서만 존재)\n",
        "    if feedback.get('llm_feedback'):\n",
        "        print(f\"\\n[LLM 보강 피드백]\")\n",
        "        print(feedback['llm_feedback'])\n",
        "\n",
        "    if feedback.get('llm_error'):\n",
        "        print(f\"\\n[LLM 오류]\")\n",
        "        print(feedback['llm_error'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeTJHWzgoXqO",
        "outputId": "e9108df2-39cf-49a7-c20b-9b105952a11f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "테스트 1: 교수님께 적절한 격식체\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "입력: \"교수님, 진로 상담을 받고 싶어서 찾아뵀습니다. 시간이 괜찮으시면 면담을 요청드려도 될까요?\"\n",
            "======================================================================\n",
            "\n",
            "[분석 결과]\n",
            "  공손성 점수: 100/100\n",
            "  판정 말투: very_polite\n",
            "  권장 말투: very_polite\n",
            "\n",
            "[점수 상세]\n",
            "  기본 점수: 50\n",
            "  종결어미: +50\n",
            "  호칭: +15\n",
            "  높임 어휘: +0\n",
            "  무례 표현: +0\n",
            "\n",
            "[탐지된 종결어미]\n",
            "  - very_polite: '습니다' (+30)\n",
            "  - polite: '요' (+20)\n",
            "\n",
            "[탐지된 호칭]\n",
            "  - '교수님' (+15)\n",
            "\n",
            "[적절성 평가]\n",
            "  상태: appropriate\n",
            "  메시지: 적절한 말투입니다!\n",
            "\n",
            "[실행 모드]\n",
            "  mode: simulation\n"
          ]
        }
      ],
      "source": [
        "# 테스트 케이스 1: 교수님께 적절한 격식체\n",
        "print(\"\\n\" + \"#\" * 70)\n",
        "print(\"테스트 1: 교수님께 적절한 격식체\")\n",
        "print(\"#\" * 70)\n",
        "\n",
        "feedback1 = get_feedback_by_mode(\n",
        "    text=\"교수님, 진로 상담을 받고 싶어서 찾아뵀습니다. 시간이 괜찮으시면 면담을 요청드려도 될까요?\",\n",
        "    recommended_formality=\"very_polite\"\n",
        ")\n",
        "print_feedback_result(feedback1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kwl2dGioXqO",
        "outputId": "a05abc6e-3799-4daa-abad-fcd413b715e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "테스트 2: 교수님께 부적절한 반말\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "입력: \"교수님, 이거 어떻게 해? 너무 어려워.\"\n",
            "======================================================================\n",
            "\n",
            "[분석 결과]\n",
            "  공손성 점수: 45/100\n",
            "  판정 말투: mixed\n",
            "  권장 말투: very_polite\n",
            "\n",
            "[점수 상세]\n",
            "  기본 점수: 50\n",
            "  종결어미: -20\n",
            "  호칭: +15\n",
            "  높임 어휘: +0\n",
            "  무례 표현: +0\n",
            "\n",
            "[탐지된 종결어미]\n",
            "  - informal: '해' (-20)\n",
            "\n",
            "[탐지된 호칭]\n",
            "  - '교수님' (+15)\n",
            "\n",
            "[적절성 평가]\n",
            "  상태: inappropriate\n",
            "  메시지: 말투가 상황에 비해 많이 낮습니다. 더 공손한 표현을 사용하세요.\n",
            "\n",
            "[개선 제안]\n",
            "  추천 표현: \"교수님, 이것은 어떻게 하면 될까요?? 너무 어려워.\"\n",
            "\n",
            "[실행 모드]\n",
            "  mode: simulation\n"
          ]
        }
      ],
      "source": [
        "# 테스트 케이스 2: 교수님께 부적절한 반말\n",
        "print(\"\\n\" + \"#\" * 70)\n",
        "print(\"테스트 2: 교수님께 부적절한 반말\")\n",
        "print(\"#\" * 70)\n",
        "\n",
        "feedback2 = get_feedback_by_mode(\n",
        "    text=\"교수님, 이거 어떻게 해? 너무 어려워.\",\n",
        "    recommended_formality=\"very_polite\"\n",
        ")\n",
        "print_feedback_result(feedback2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAo6-INxoXqO",
        "outputId": "522006ea-9c2c-4026-b523-5c37c12c2c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "테스트 3: 선배에게 적절한 존댓말\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "입력: \"선배님, 오늘 팀플 회의 몇 시예요? 제가 좀 늦을 것 같아요.\"\n",
            "======================================================================\n",
            "\n",
            "[분석 결과]\n",
            "  공손성 점수: 100/100\n",
            "  판정 말투: very_polite\n",
            "  권장 말투: polite\n",
            "\n",
            "[점수 상세]\n",
            "  기본 점수: 50\n",
            "  종결어미: +40\n",
            "  호칭: +15\n",
            "  높임 어휘: +0\n",
            "  무례 표현: +0\n",
            "\n",
            "[탐지된 종결어미]\n",
            "  - polite: '예요' (+20)\n",
            "  - polite: '요' (+20)\n",
            "\n",
            "[탐지된 호칭]\n",
            "  - '선배님' (+15)\n",
            "\n",
            "[적절성 평가]\n",
            "  상태: very_polite\n",
            "  메시지: 매우 공손한 표현입니다! 상황에 따라 조금 편하게 말해도 괜찮아요.\n",
            "\n",
            "[실행 모드]\n",
            "  mode: simulation\n"
          ]
        }
      ],
      "source": [
        "# 테스트 케이스 3: 선배에게 적절한 존댓말\n",
        "print(\"\\n\" + \"#\" * 70)\n",
        "print(\"테스트 3: 선배에게 적절한 존댓말\")\n",
        "print(\"#\" * 70)\n",
        "\n",
        "feedback3 = get_feedback_by_mode(\n",
        "    text=\"선배님, 오늘 팀플 회의 몇 시예요? 제가 좀 늦을 것 같아요.\",\n",
        "    recommended_formality=\"polite\"\n",
        ")\n",
        "print_feedback_result(feedback3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz-qosMSoXqP",
        "outputId": "97cc355b-eaea-43a8-d9fa-e1aa406b474b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "테스트 4: 친구에게 적절한 반말\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "입력: \"수진아, 오늘 뭐해? 카페 갈래?\"\n",
            "======================================================================\n",
            "\n",
            "[분석 결과]\n",
            "  공손성 점수: 20/100\n",
            "  판정 말투: informal\n",
            "  권장 말투: informal\n",
            "\n",
            "[점수 상세]\n",
            "  기본 점수: 50\n",
            "  종결어미: -20\n",
            "  호칭: -10\n",
            "  높임 어휘: +0\n",
            "  무례 표현: +0\n",
            "\n",
            "[탐지된 종결어미]\n",
            "  - informal: '해' (-20)\n",
            "\n",
            "[탐지된 호칭]\n",
            "  - '수진아' (-10)\n",
            "\n",
            "[적절성 평가]\n",
            "  상태: appropriate\n",
            "  메시지: 적절한 말투입니다!\n",
            "\n",
            "[실행 모드]\n",
            "  mode: simulation\n"
          ]
        }
      ],
      "source": [
        "# 테스트 케이스 4: 친구에게 적절한 반말\n",
        "print(\"\\n\" + \"#\" * 70)\n",
        "print(\"테스트 4: 친구에게 적절한 반말\")\n",
        "print(\"#\" * 70)\n",
        "\n",
        "feedback4 = get_feedback_by_mode(\n",
        "    text=\"수진아, 오늘 뭐해? 카페 갈래?\",\n",
        "    recommended_formality=\"informal\"\n",
        ")\n",
        "print_feedback_result(feedback4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZmQr8R_oXqP",
        "outputId": "97b42291-8a95-4532-e85f-14afef976571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "테스트 5: 친구에게 과도한 존댓말\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "입력: \"수진님, 오늘 시간이 되시면 카페에 가시겠습니까?\"\n",
            "======================================================================\n",
            "\n",
            "[분석 결과]\n",
            "  공손성 점수: 95/100\n",
            "  판정 말투: very_polite\n",
            "  권장 말투: informal\n",
            "\n",
            "[점수 상세]\n",
            "  기본 점수: 50\n",
            "  종결어미: +30\n",
            "  호칭: +15\n",
            "  높임 어휘: +0\n",
            "  무례 표현: +0\n",
            "\n",
            "[탐지된 종결어미]\n",
            "  - very_polite: '습니까' (+30)\n",
            "\n",
            "[탐지된 호칭]\n",
            "  - '수진님' (+15)\n",
            "\n",
            "[적절성 평가]\n",
            "  상태: very_polite\n",
            "  메시지: 매우 공손한 표현입니다! 상황에 따라 조금 편하게 말해도 괜찮아요.\n",
            "\n",
            "[실행 모드]\n",
            "  mode: simulation\n"
          ]
        }
      ],
      "source": [
        "# 테스트 케이스 5: 친구에게 과도한 존댓말\n",
        "print(\"\\n\" + \"#\" * 70)\n",
        "print(\"테스트 5: 친구에게 과도한 존댓말\")\n",
        "print(\"#\" * 70)\n",
        "\n",
        "feedback5 = get_feedback_by_mode(\n",
        "    text=\"수진님, 오늘 시간이 되시면 카페에 가시겠습니까?\",\n",
        "    recommended_formality=\"informal\"\n",
        ")\n",
        "print_feedback_result(feedback5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmC5e9DboXqP"
      },
      "source": [
        "## 7. 향후 확장: LLM 기반 피드백\n",
        "\n",
        "### 7.1 확장 계획\n",
        "\n",
        "현재 규칙 기반 피드백의 한계:\n",
        "- 제한된 패턴만 탐지 가능\n",
        "- 문맥을 고려하지 못함\n",
        "- 자연스러운 대안 표현 생성 어려움\n",
        "\n",
        "LLM 기반으로 확장 시 개선 사항:\n",
        "- 문맥을 고려한 공손성 분석\n",
        "- 자연스러운 대안 표현 생성\n",
        "- 학습자 수준에 맞는 설명 제공\n",
        "- 문화적 뉘앙스 설명\n",
        "\n",
        "### 7.2 LLM 연동 예시 (향후 구현)\n",
        "\n",
        "```python\n",
        "# HyperCLOVA X API 연동 예시 (향후 구현)\n",
        "def generate_llm_feedback(text, recommended, actual, score):\n",
        "    prompt = f\"\"\"\n",
        "    사용자 발화: \"{text}\"\n",
        "    권장 말투: {recommended}\n",
        "    실제 말투: {actual}\n",
        "    공손성 점수: {score}/100\n",
        "    \n",
        "    이 발화에 대해 피드백을 제공하세요.\n",
        "    더 적절한 표현이 있다면 제안해주세요.\n",
        "    \"\"\"\n",
        "    # API 호출\n",
        "    response = clova_api.generate(prompt)\n",
        "    return response\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP-ak3K2oXqQ"
      },
      "source": [
        "## 8. 정리\n",
        "\n",
        "### 8.1 이 모듈에서 구현한 것\n",
        "\n",
        "1. **종결어미 패턴 정의**: very_polite, polite, informal 3단계\n",
        "2. **호칭 패턴 정의**: 님, 씨, 아/야\n",
        "3. **KoreanPolitenessAnalyzer**: 공손성 점수 계산기\n",
        "4. **AppropriatenessEvaluator**: 적절성 평가기\n",
        "5. **PolitenessFeedbackSystem**: 통합 피드백 시스템\n",
        "\n",
        "### 8.2 향후 확장 계획\n",
        "\n",
        "1. **AI-Hub 데이터 연동**: 실제 대화 패턴 학습\n",
        "2. **LLM 기반 피드백**: HyperCLOVA X 연동\n",
        "3. **음성 분석 통합**: CLOVA Speech STT 결과 활용\n",
        "4. **개인화**: 사용자별 실수 패턴 학습\n",
        "\n",
        "### 8.3 다음 단계\n",
        "\n",
        "다음 데모에서는 LLM 프롬프트 엔지니어링을 다룹니다. 아바타 대화 생성, 피드백 생성 등에 사용되는 프롬프트를 상세히 분석합니다."
      ]
    }
  ]
}